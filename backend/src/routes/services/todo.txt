
HERE WHAT I DID:

what i did rn for sse, it works just issues and its rough:
so basically we hit backend /start it makes outline and first step and sends it to frontend
also creates a session in memory, which has id, prompt, outline, what step we on, previous step for context for the llm whatever
and session also has 'subscribers' rn its empty

so after it does the first step then frontend hits the backend /stream with session id, and then it adds my frontend as a subscriber
and then it starts the sessionRunner which gets session info using the id i passed through, it sees the outline, what step its on, prev step and sends it
to generate the next step and then it broadcasts it, a fancy way of saying it fucking just writes it through the stream to the subscriber (frontend)

then theres lots of error handling, when its done delete session delete subscriber
just understand all ts make sure it makes sense cuz its rough rn

WHAT I DID:
- planschema basically i found that long ass prompt the ai cant generate a explanation with visuals its way too much to ask
so basically i made a plan schema and planprompt so in the generate step function it creates an entire plan for the step
and then makes the actual explanation + visuals json to send back to frontend so the ai doesnt have to think so much for
each step it can break it down into multiple calls to make it easier 
- i also made schemas for each prop it works ok sometimes its a little weird but thats so the frontend doesnt receive
absolute aids when trying to render props on the screen
- few bug fixes here and there



QUICK SUMMARY

1. also yk maybe fuck around with the prompt if u want to get it faster after the whole sse is done and fuck around with diff models
2. also fucking look into like how we can make sure the math is right at the very end maybe a math model idk

WHAT WE NEED TO DO:
- Fix frontend ui its so shit lol and theres alot of errors that popup the voice to text doesnt say stuff properly sometimes and the whiteboard doesnt output the text right
- uh the prompt i changed a bit its better but we need to make it easier for the user to understand and interact like rn it doesnt feel like its actually teaching
it feels like its spewing random ass garbage at u
- AI needs to be able to make its own axis and graph labels because it tries to explain angles in standard position with a normal x-y graph its retarded
- functions probably need constraints because ai cant properly draw triangles or anything to explain stuff (also the ai explanation dont match)
    - experimented with sm models and diff promps but big issue like the ai will say like lets visualize a triangle but then plot a sin function or something that doesnt help in that step
    - ai also doesnt use the camera function at all always the same static camera

need to have animations not just all start at the beginning. try to have timing maybe between text/narration/animations?
we dont have that wow factor like rn technically its doing what we say but the visuals dont actually help teach when u look at it

SAFIULLAH INSHALLAH
HOLA HERES QUICK SUMMARY:
1. fuck the audio for now thats an easy fix ill fix it Later
2. templates we add later\
3. diff scene types ill add later, like 2d graph and axes, empty, unit circle etc. (in plan)

DO THIS STUFF BEFORE MAKING A BRANCH AND MESSING AROUND WITH Frontend
1. add line + secant line two new primitives (like function, shade area etc.) to prompt and schema
2. make the prompt nicer so much tokens ask gpt how u can optimize maybe remove some uncenssary fields and other random shit
3. and maybe go back to single call per step
4. just go back to old backend mostly theres sm garbage it outputs, keep schema stuff and wtv else u added just fix
the prompt and like the two calls per step keep ai job to a minimum
like for example removing before adding i sent u a vid on why thats not great lmao its so funny
5. like idk why the subttiles it generates r so repetitive and ass before it seemed fine i think the method before was lowkey better
thanks my fella


FRONTEND SO FAR
 im brainstorming random stuff i could do
 one thing is FOR CAMERA:
 - ai cannot control a camera its so bad and it just doesnt do it
 - oculd do it mathematically i could see where the function is or intersection points and autocompute where camera should go
 - im gonna experiment with it
 FOR TIMING:
 - im still thinking brah
 - maybe based on the words or nah
 - or like default time between actions so not all at once at least 
 